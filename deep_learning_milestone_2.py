# -*- coding: utf-8 -*-
"""deep learning milestone - 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fzQ20hwac_cTBB3VoyvjuyAkFYV_0nev
"""

#name: urba muskaan
#student id:URB22608789

#https://www.kaggle.com/datasets/nih-chest-xrays/sample/code

import pandas as pd
metadata = pd.read_csv("/content/drive/MyDrive/sample/sample_labels.csv")

from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Split the dataset into train, validation, and test sets
train_df, test_df = train_test_split(metadata, test_size=0.2, random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)

# Data augmentation
train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

batch_size = 16

train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,
                                                    x_col='Image Index',
                                                    y_col='Finding Labels',
                                                    target_size=(256, 256),
                                                    batch_size=batch_size,
                                                    class_mode='categorical')

val_generator = val_datagen.flow_from_dataframe(dataframe=val_df,
                                                x_col='Image Index',
                                                y_col='Finding Labels',
                                                target_size=(256, 256),
                                                batch_size=batch_size,
                                                class_mode='categorical')

test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,
                                                  x_col='Image Index',
                                                  y_col='Finding Labels',
                                                  target_size=(256, 256),
                                                  batch_size=batch_size,
                                                  class_mode='categorical')

!pip install keras-preprocessing

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Attention, Input

# Assuming you have an input tensor named input_tensor
input_tensor = Input(shape=(256, 256, 3))

# Example convolutional layers
conv1 = Conv2D(32, (3, 3), activation='relu')(input_tensor)
conv2 = Conv2D(64, (3, 3), activation='relu')(conv1)

# Flatten the output tensor
flatten_tensor = Flatten()(conv2)

# Dense layer
dense_tensor = Dense(128, activation='relu')(flatten_tensor)

# Output layer
output_tensor = Dense(1, activation='sigmoid')(dense_tensor)

# Define the model
model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Display the model summary
model.summary()

import pandas as pd
from keras_preprocessing.image import ImageDataGenerator

# Load the CSV file containing image paths and labels
train_df = pd.read_csv('/content/drive/MyDrive/sample/sample_labels.csv')


image_directory = '/content/drive/MyDrive/sample/images'

# Initialize ImageDataGenerator
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # if you have a validation split
)

# Define train generator
batch_size = 32
train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,
                                                    directory=image_directory,
                                                    x_col='Image Index',
                                                    y_col='Finding Labels',
                                                    batch_size=batch_size,
                                                    shuffle=True,
                                                    class_mode='categorical')

import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input

# Define your model architecture
input_tensor = Input(shape=(256, 256, 3))

conv1 = Conv2D(32, (3, 3), activation='relu')(input_tensor)
flatten_tensor = Flatten()(conv1)
dense_tensor = Dense(128, activation='relu')(flatten_tensor)
output_tensor = Dense(1, activation='sigmoid')(dense_tensor)
model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_generator,
                    steps_per_epoch=len(train_generator),
                    epochs=10,
                    batch_size=32)

# Save the model
model.save('chest_xray_classifier.h5')

import pandas as pd
from keras_preprocessing.image import ImageDataGenerator

# Load the CSV file containing image paths and labels
test_df = pd.read_csv('/content/drive/MyDrive/sample/sample_labels.csv')

# Directory containing the test images
image_directory = '/content/drive/MyDrive/sample/images'

# Initialize ImageDataGenerator for test data
test_datagen = ImageDataGenerator(rescale=1./255)

# Define batch size
batch_size = 32

# Define test generator
test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    directory=image_directory,
    x_col='Image Index',
    y_col='Finding Labels',
    target_size=(256, 256),  # Adjust target size if needed
    batch_size=batch_size,
    class_mode='categorical',  # Adjust class mode based on your task
    shuffle=False  # Do not shuffle test data
)

# Check generator configuration
print("Test generator configuration:")
print("Number of samples:", test_generator.samples)
print("Batch size:", test_generator.batch_size)
print("Class indices:", test_generator.class_indices)

# Check the first batch of data
images, labels = test_generator.next()
print("First batch of images shape:", images.shape)
print("First batch of labels shape:", labels.shape)

# Evaluate the model on the test set
evaluation_metrics = model.evaluate(test_generator)

# Print the evaluation metrics
print("Evaluation Metrics:", evaluation_metrics)

# Generate predictions
predictions = model.predict(test_generator)

# Plot training loss
plt.plot(history.history['loss'], label='Training Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

import numpy as np
import tensorflow as tf
from tensorflow import keras

# Step 1: Create synthetic data
num_samples = 1000
input_shape = (32,)  # Input shape of the data
num_classes = 10

# Generate synthetic training data
train_data = np.random.random((num_samples, *input_shape))
train_labels = np.random.randint(num_classes, size=(num_samples,))

# Generate synthetic validation data
val_data = np.random.random((num_samples // 2, *input_shape))
val_labels = np.random.randint(num_classes, size=(num_samples // 2,))

# Step 2: Define a simple neural network model
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=input_shape),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(num_classes, activation='softmax')
])

# Step 3: Compile the model
optimizer = keras.optimizers.Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Step 4: Train the model
history = model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))

# Step 5: Identify and resolve any errors encountered during training